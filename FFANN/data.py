import h5py
import numpy as np
import torch
from torch.utils.data import ConcatDataset
import hashlib


class File(h5py.File):
    """Represents a HDF5 file with simulation data, generated by `Combo FANS` (https://github.tik.uni-stuttgart.de/ac135187/combo_fans3d).

    This class provides access to the microstructure groups (:class:`mlprum.data.MicrostructureGroup`) in the file,
    which itself contain multiple datasets (:class:`mlprum.data.Dataset`) with simulation data.
    It inherits from :class:`h5py.File`. See the `h5py` documentation for further information.
    """    
    def __init__(self, file_name, mode='r'):
        """Constructor of the class. Open the file with given file path.

        Example:
            >>> file_name = 'wcu_random_rve_noise.h5'
            >>> file = data.File(file_name)

        :param file_name: Path of the file
        :type file_name: str
        :param mode: File mode ('w': write, 'r':read, 'a': append), defaults to 'r'
        :type mode: str, optional
        """        
        super().__init__(file_name, mode)

    def group_names(self):
        """Get all group names of the HDF5 file. A microstructure group can contain multiple datasets.

        Example:
            >>> file = data.File(file_name)
            >>> print(file.group_names())
            ['ms_random']

        :return: List of group names
        :rtype: list
        """        
        groups = list(self.file.keys())
        return groups

    def group(self, group_name):
        """Get a microstructure group in the HDF5 file with given name.

        :param group_name: Name of the group
        :type group_name: str
        :return: Group with given name
        :rtype: :class:`mlprum.data.MicrostructureGroup`
        """        
        ms = MicrostructureGroup(self, group_name)
        return ms


class MicrostructureGroup:
    """Represents a microstructure group in a HDF5 file with simulation data, generated by `Combo FANS`.

    A microstructure can contain multiple datasets (:class:`mlprum.data.Dataset`) with simulation data.
    """    
    def __init__(self, file, group_name):
        """Constructor of the class. Extract a microstructure with given group name from a given HDF5 file.

        :param file: File that contains the microstructure
        :type file: :class:`mlprum.data.File`
        :param group_name: Group name of the microstructure
        :type group_name: str
        :raises KeyError: If the group with given name does not exist in the given file
        """        
        self.file = file
        self.group_name = group_name
        try:
            self.group = self.file[group_name]
        except KeyError as e:
            groups = list(self.file.keys())
            print(f'Group {group_name} not found in file {self.file.filename}!')
            print(f'Available groups in HD5 file: {groups}')
            raise e
    
    def dataset_names(self):
        """Get the names of all datasets in the microstructure group that contain simulation data.

        Example:
            >>> ms_group = data.File(file_name).group('ms_random')
            >>> print(ms_group.dataset_names())
            ['dset0', 'dset1', 'dset2', ...]

        :return: List of dataset names
        :rtype: list
        """        
        keys = list(self.group.keys())
        dset_list = [k.replace('_sol', '').replace('_sim', '') for k in keys if k.endswith('_sol') or k.endswith('_sim')]
        return dset_list

    def dataset(self, dset_name):
        """Extract a dataset with given name from the microstructure.

        :param dset_name: Name of the dataset
        :type dset_name: str
        :return: Dataset with given name
        :rtype: :class:`mlprum.data.Dataset`
        """        
        dset = self.group[dset_name]
        dset_sol = self.solution_dataset(dset_name)
        return Dataset(dset, dset_sol)

    def datasets(self):
        """Concatenate all datasets from the microstructure and return it.

        :return: Dataset that contains all datasets from the microstructure.
        :rtype: :class:`torch.utils.data.ConcatDataset`
        """        
        dset = ConcatDataset([self.dataset(k) for k in self.dataset_names()])
        return dset

    def solution_dataset(self, dset_name):
        if dset_name + '_sol' in self.group.keys():
            return self.group[dset_name + '_sol']
        if dset_name + '_sim' in self.group.keys():
            return self.group[dset_name + '_sim']
        raise Exception(f'Solution for dataset `{dset_name}` could not be found!')


class Dataset(torch.utils.data.Dataset):
    """Represents a dataset in a microstructure from a HDF5 file with simulation data, generated by `Combo FANS`.

    The dataset can contain multiple simulation data points, e.g. simulation results for multiple temperature values.
    This class inherits from :class:`torch.utils.data.Dataset` and can therefore be used directly in a Machine Learning pipeline
    that is based on the `PyTorch` framework.

    The dataset contains the material parameters as data for the input features in the attribute :code:`x` and
    the simulated effective parameters as data for the output features in the attribute :code:`y`.
    """    
    def __init__(self, dset, dset_sol):
        """Constructor of the class. Create a `PyTorch` dataset from given HDF5 file groups.

        :param dset: HDF5 dataset that contains data regarding the RVE and the material parameters
        :type dset: :class:`h5py.Group`
        :param dset_sol: HDF5 dataset that contains the simulation results
        :type dset_sol: :class:`h5py.Group`
        """        
        self.dset = dset
        self.dset_sol = dset_sol

        self.x = torch.Tensor(self.parameters())
        self.y = torch.Tensor(self.eff_parameters())

    def __len__(self):
        """Get the length of the dataset, i.e. how many data points it contains.

        :return: Length of the dataset
        :rtype: int
        """        
        return len(self.x)

    def __getitem__(self, idx):
        """Fetch a data point with given index from the dataset

        :param idx: Index of the data point
        :type idx: int
        :return: Tuple of material parameters (for the input features) and effective parameters (for the output features)
        :rtype: tuple
        """        
        item = (self.x[idx], self.y[idx])
        return item

    def solution_keys(self):
        """Get the solution keys of the dataset.
        
        A solution key is usually a temperature value and represents a data point of the simulation data.

        Example:
            >>> dataset = data.File(file_name).group('ms_random').dataset('dset0')
            >>> print(dataset.solution_keys())
            array([ 293.,  393.,  493.,  593., ...])

        :return: `NumPy` array with all solution keys
        :rtype: :class:`numpy.ndarray`
        """        
        key_list = list(self.dset_sol.keys())
        key_set = sorted(list(set([float(k[-7:]) for k in key_list if self.is_float(k[-7:])])))
        keys = np.array(key_set)
        return keys

    def parameters(self, solution_keys=None):
        """Get the parameters (input features) in flattened vector notation for the specified data points.

        The resulting vector can be used as input data for a Machine Learning model.
        It has the shape :code:`(N, in_dim)` where :code:`N` is the number of data points and :code:`in_dim` is the number of input features.

        Example:
            >>> dataset = data.File(file_name).group('ms_random').dataset('dset0')
            >>> print(ms_group.parameters(293))
            array([[3.20371725, 0.33239053, 0.28694471, ...]])

        :param solution_keys: List of the solution keys for which data points are to be returned, defaults to None (i.e. all data points are returned)
        :type solution_keys: list, optional
        :return: `NumPy` array with the parameters in flattened vector notation for the specified data points
        :rtype: :class:`nupmy.ndarray`
        """        
        if solution_keys is None:
            solution_keys = self.solution_keys()
        if np.isscalar(solution_keys):
            solution_keys = np.array([solution_keys])
        else:
            solution_keys = np.array(solution_keys)
        
        params = np.array([float(k) for k in np.nditer(solution_keys)])
        """
        params = [self.flatten_concat((
            self.elastic_modulus(k),
            self.poisson_ratio(k),
            self.thermal_exp(k),
            self.conductivity(k),
            self.heat_capacity(k),
            self.density,
            self.volume_fraction
        )) for k in np.nditer(solution_keys)]
        """
        params = params.reshape((-1,1)) if params.ndim == 1 else params
        params_array = np.stack(params)
        return params_array

    def eff_parameters(self, solution_keys=None):
        """Get the effective parameters (output features) in flattened vector notation for the specified data points.

        The resulting vector can be used directly as target data for a Machine Learning model.
        It has the shape :code:`(N, out_dim)` where :code:`N` is the number of data points and :code:`out_dim` is the number of input features.

        Example:
            >>> dataset = data.File(file_name).group('ms_random').dataset('dset0')
            >>> print(dataset.eff_parameters([293, 1093]))
            array([[3.20371725, 0.33239053, 0.28694471, ...],
            [8.13823321, 0.34208868, 0.28179643, 0.26321487, ...]])

        :param solution_keys: List of the solution keys for which data points are to be returned, defaults to None (i.e. all data points are returned)
        :type solution_keys: list, optional
        :return: `NumPy` array with the effective parameters in flattened vector notation for the specified data points
        :rtype: :class:`numpy.ndarray`
        """        
        if solution_keys is None:
            solution_keys = self.solution_keys()
        if not isinstance(solution_keys, list):
            solution_keys = [solution_keys]
        else:
            solution_keys = np.array(solution_keys)
        
        params = [self.flatten_concat((
            self.cholesky(self.eff_stiffness(k)),
            self.eff_thermal_strain(k)
            #self.eff_thermal_exp(k),
            #self.cholesky(self.eff_conductivity(k)),
            #self.eff_heat_capacity(k),
            #self.eff_density
        )) for k in np.nditer(solution_keys)]
        params_array = np.stack(params)
        return params_array

    def parameter_names(self):
        """Get the names of the available parameters (input features) in the dataset.

        :return: List of the parameter names
        :rtype: list
        """        
        params_list = list(self.dset.attrs.keys())
        return params_list

    def parameter(self, param_name):
        """Get a parameter (input feature) with given name from the dataset.

        Typically, it is a material parameter or contains information about the microstructure.
        The returned parameter is valid for the entire dataset, e.g. volume fraction of the microstructure.

        :param param_name: Name of the parameter
        :type param_name: str
        :return: Parameter of the dataset.
        :rtype: object
        """        
        param = self.dset.attrs[param_name]
        return param

    def solution_parameter(self, param_name, solution_key):
        """Get a parameter (input feature) with given name for a data point with given solution key.

        Typically, it is a material parameter, that changes across the data points.
        The returned parameter is only valid for the specified data point, e.g. conductivity at a specific temperature.

        A solution key is an identifier for a data point and usually indicates its temperature.
        The solution key is expected to be a `float` that is formatted as `str` with the formatter :code:`'07.2f'`.
        See `Combo FANS` for further information.

        :param param_name: Name of the parameter
        :type param_name: str
        :param solution_key: Solution key of the data point, usually temperature.
        :type solution_key: str
        :return: Solution parameter of the data point.
        :rtype: object
        """        
        try:
            key = f"conductivity_{solution_key:07.2f}"
            return self.dset_sol[key].attrs[param_name]
        except:
            try:
                return self.dset_sol[f'material_{solution_key:07.2f}'].attrs[param_name]
            except:
                raise Exception(f'Parameter `{param_name}` for data point `{solution_key}` could not be found!')

    def effective_parameter(self, param_name, solution_key):
        """Get an effective parameter (output feature) with given name from a data point with given solution key.

        Typically, it is a effective material parameter, that changes across the data points.
        The returned parameter is only valid for the specified data point, e.g. effective conductivity at a specific temperature.

        A solution key is an identifier for a data point and usually indicates its temperature.
        The solution key is expected to be a `float` that is formatted as `str` with the formatter '07.2f'.
        See `Combo FANS` for further information.

        :param param_name: Name of the effective parameter.
        :type param_name: str
        :param solution_key: Solution key of the data point, usually temperature.
        :type solution_key: str
        :return: Effective parameter of the data point.
        :rtype: object
        """ 
        try:
            key = f"{param_name}_{solution_key:07.2f}"
            return self.dset_sol[key]
        except:
            try:
                key = f"eff_{param_name}_{solution_key:07.2f}"
                return self.dset_sol[key]
            except:
                raise Exception(f'Effective parameter `{param_name}` for data point `{solution_key}` could not be found!')

    @property
    def temperature(self, solution_key=None):
        """Property, that specifies the temperature of the dataset.

        :return: Temperature
        :rtype: float
        """        
        if solution_key is not None:
            return float(solution_key)
        theta = self.parameter('temperature')
        return float(theta)

    @property
    def volume_fraction(self):
        """Property, that specifies the volume fraction of the dataset.

        The volume fraction refers to the reinforcement material, e.g. :math:`f_1 \in (0, 1)`.

        :return: Volume fraction of the microstructure
        :rtype: float
        """        
        try:
            return self.dset_sol.attrs['volume_fraction'][1]
        except:
            try:
                return self.dset_sol.attrs['combo_volume_fraction'][1]
            except:
                print('Property `volume fraction` could not be found!')

    @property
    def density(self):
        """Property, that specifies a dimensionless quantity of the density in the composite material.

        The dimensionless quantity is given by :math:`\\frac{\\rho_1}{\\rho_0}`.
        In the current implementation, only the density of WCu (Copper-tungsten composite) is considered!

        :return: Dimensionless quantity of the density in the composite material
        :rtype: float
        """        
        density_wsc = 1.93000e-05
        density_cu = 8.93300e-06
        rho = density_wsc / density_cu
        return rho

    def conductivity(self, solution_key):
        """Get a dimensionless quantity for the conductivity in the composite material for a data point.

        The dimensionless quantity is given by :math:`\\frac{\\kappa_1}{\\kappa_0}`.

        :param solution_key: Solution key, that specifies the data point
        :type solution_key: str
        :return: Dimensionless quantity for the conductivity in the composite material for a data point
        :rtype: float
        """        
        kappa = self.solution_parameter('conductivity', solution_key)[1]
        return kappa

    def elastic_modulus(self, solution_key):
        """Get a dimensionless quantity for the elastic modulus in the composite material for a data point.

        The dimensionless quantity is given by :math:`\\frac{E_1}{E_0}`.

        :param solution_key: Solution key, that specifies the data point
        :type solution_key: str
        :return: Dimensionless quantity for the elastic modulus in the composite material for a data point
        :rtype: float
        """
        E = self.solution_parameter('elastic_modulus', solution_key)[1]
        return E

    def poisson_ratio(self, solution_key):
        """Get the poisson ratios in the composite material for a data point.

        The poisson ratios are given by :math:`\\nu_0, \\nu_1`.

        :param solution_key: Solution key, that specifies the data point
        :type solution_key: str
        :return: List of the poisson ratios in the composite material for a data point, i.e. :code:`[nu_0, nu_1]`
        :rtype: list
        """
        nu = self.solution_parameter('poisson_ratio', solution_key)[:]
        return nu

    def thermal_exp(self, solution_key):
        """Get a dimensionless quantity for the thermal expansion in the composite material for a data point.

        The dimensionless quantity is given by :math:`\\frac{\\alpha_1}{\\alpha_0}`.

        :param solution_key: Solution key, that specifies the data point
        :type solution_key: str
        :return: Dimensionless quantity for the thermal expansion in the composite material for a data point
        :rtype: float
        """
        cte = self.solution_parameter('thermal_expansion', solution_key)[1]
        return cte

    def thermal_strain(self, solution_key):
        """Get a dimensionless quantity for the thermal expansion in the composite material for a data point.

        The dimensionless quantity is given by :math:`\\frac{\\alpha_1}{\\alpha_0}`.

        :param solution_key: Solution key, that specifies the data point
        :type solution_key: str
        :return: Dimensionless quantity for the thermal expansion in the composite material for a data point
        :rtype: float
        """
        cte = self.solution_parameter('thermal_strain', solution_key)[1]
        return cte

    def heat_capacity(self, solution_key):
        """Get a dimensionless quantity for the heat capacity in the composite material for a data point.

        The dimensionless quantity is given by :math:`\\frac{c_1}{c_0}`.

        :param solution_key: Solution key, that specifies the data point
        :type solution_key: str
        :return: Dimensionless quantity for the heat capacity in the composite material for a data point
        :rtype: float
        """
        rho_c = self.solution_parameter('heat_capacity', solution_key)[1]
        c = rho_c / self.density
        return c

    def eff_conductivity(self, solution_key):
        """Get the effective conductivity tensor :math:`\\mathbf{\\kappa}_\\mathrm{eff} \\in \\mathbb{R}^{3 \\times 3}` for a data point.

        :param solution_key: Solution key, that specifies the data point
        :type solution_key: str
        :return: Effective conductivity tensor for a data point as `NumPy` array with shape :code:`(3, 3)`
        :rtype: :class:`numpy.ndarray`
        """
        kappa = self.effective_parameter('conductivity', solution_key)[:]
        return kappa

    def eff_stiffness(self, solution_key):
        """Get the effective stiffness tensor :math:`\\mathbb{C}_\\mathrm{eff}` for a data point.

        The stiffness tensor is returned in normalized Voigt notation,
        i.e. :math:`\\underline{\\underline{\\hat{C}}}_\\mathrm{eff} \\in \\mathbb{R}^{6 \\times 6}`.

        See :meth:`mlprum.data.Dataset.normalized_voigt`.

        :param solution_key: Solution key, that specifies the data point
        :type solution_key: str
        :return: Effective stiffness tensor for a data point as `NumPy` array with shape :code:`(6, 6)`
        :rtype: :class:`numpy.ndarray`
        """
        C_hat = self.effective_parameter('stiffness', solution_key)[:]
        C_hat = C_hat.T # matlab saves the stiffness tensor transposed to the hdf5 file
        return C_hat

    def eff_thermal_exp(self, solution_key):
        """Get the effective coefficient of thermal expansion tensor :math:`\\mathbf{\\alpha}_\\mathrm{eff} \\in \\mathbb{R}^{3 \\times 3}` for a data point.

        Only the diagonal elements of the coefficient of thermal expansion tensor are returned, since all other elements are zero,
        i.e. :math:`\\underline{\\hat{A}}_\\mathrm{eff} \\in \\mathbb{R}^{3}`.

        :param solution_key: Solution key, that specifies the data point
        :type solution_key: str
        :return: Effective coefficient of thermal expension tensor for a data point as `NumPy` array with shape :code:`(3)`
        :rtype: :class:`numpy.ndarray`
        """
        cte = self.effective_parameter('thermal_exp', solution_key)[:]
        return cte# / 10e-6

    def eff_thermal_strain(self, solution_key):
        """Get the effective thermal strain tensor :math:`\\mathbf{\\alpha}_\\mathrm{eff} \\in \\mathbb{R}^{3 \\times 3}` for a data point.

        :param solution_key: Solution key, that specifies the data point
        :type solution_key: str
        :return: Thermal strain tensor for a data point in Voigt notation as `NumPy` array with shape :code:`(6)`
        :rtype: :class:`numpy.ndarray`
        """
        ts = self.effective_parameter('thermal_strain', solution_key)[:]
        return ts# / 10e-6

    def eff_heat_capacity(self, solution_key):
        """Get the effective heat capacity :math:`c_\\mathrm{eff}` for a data point.

        :param solution_key: Solution key, that specifies the data point
        :type solution_key: str
        :return: Effective heat capacity for a data point
        :rtype: float
        """
        # volumetric heat capacity provided by Combo FANS:
        s_eff = self.effective_parameter('heat_capacity', solution_key)[:]
        c_eff = s_eff / self.eff_density
        #c = (1-self.volume_fraction) + self.volume_fraction*self.heat_capacity(solution_key)
        return c_eff

    @property
    def eff_density(self):
        """Property, that specifies the effective density :math:`\\rho_\\mathrm{eff}` of the dataset.

        :return: Effective density of the dataset.
        :rtype: float
        """        
        rho = (1-self.volume_fraction) + self.volume_fraction*self.density
        return rho

    @staticmethod
    def parse_parameters(params):
        """Parse a flattened vector of parameters (input features) and return the separate quantities.

        See :meth:`mlprum.data.Dataset.print_parameters` for a human-readable output.

        :param params: Flattened vector of parameters (input features)
        :type params: :class:`numpy.ndarray` with shape :code:`(1)`
        :return: Tuple (E, nu, alpha, kappa, c, rho, f1)
        :rtype: tuple
        """        
        params = params.flatten()
        theta = params[0]
        return theta
        """
        E = params[0]
        nu = params[1:3]
        alpha = params[3]
        kappa = params[4]
        c = params[5]
        rho = params[6]
        f1 = params[7]
        return E, nu, alpha, kappa, c, rho, f1
        """

    @staticmethod
    def parse_eff_parameters(params):
        """Parse a flattened vector of effective parameters (output features) and return the separate quantities.

        See :meth:`mlprum.data.Dataset.print_eff_parameters` for a human-readable output.

        :param params: Flattened vector of parameters (input features)
        :type params: :class:`numpy.ndarray` with shape :code:`(27)`
        :return: Tuple (C, kappa, alpha, c, rho)
        :rtype: tuple
        """        
        params = params.flatten()
        C = __class__.reverse_cholesky(params[0:21])
        ts = params[21:27]
        return C, ts
        """
        alpha = params[21:27]
        kappa = __class__.reverse_cholesky(params[27:33])
        c = params[33]
        rho = params[34]
        return C, kappa, alpha, c, rho
        """

    @staticmethod
    def flatten_concat(arrays):
        """Flatten the given arrays and concatenate the results to a single vector.

        :param arrays: List of :class:`numpy.ndarray` arrays
        :type arrays: list
        :return: Flattened vector
        :rtype: :class:`numpy.ndarray`
        """        
        flattened = [a.flatten() if isinstance(a, np.ndarray) else np.array(a) for a in arrays]
        return np.hstack(flattened)

    @staticmethod
    def normalized_voigt(array):
        """Compute the normalized Voigt (Mandel) notation (https://en.wikipedia.org/wiki/Voigt_notation#Mandel_notation)
        for a given `NumPy` array.

        The inverse function is given by :meth:`mlprum.data.Dataset.reverse_voigt`.

        :param array: `NumPy` array with shape :code:`(3, 3)`
        :type array: :class:`numpy.ndarray`
        :raises NotImplementedError: if shape is not :code:`(3, 3)`
        :return: `Numpy` array with the normalized Voigt (Mandel) notation and shape :code:`(6)`
        :rtype: :class:`numpy.ndarray`
        """        
        array_hat = np.empty(6)
        if array.shape == (3,3):
            array_hat = np.array(
                [array[0,0],
                array[1,1],
                array[2,2],
                np.sqrt(2)*array[1,0],
                np.sqrt(2)*array[2,0],
                np.sqrt(2)*array[2,1]]
            )
        else:
            raise NotImplementedError
        return array_hat

    @staticmethod
    def reverse_voigt(array):
        """Compute the reversed normalized Voigt (Mandel) notation (https://en.wikipedia.org/wiki/Voigt_notation#Mandel_notation)
        for a given `NumPy` array.

        The inverse function is given by :meth:`mlprum.data.Dataset.normalized_voigt`.

        :param array: `Numpy` array with the normalized Voigt (Mandel) notation and shape :code:`(6)`
        :type array: :class:`numpy.ndarray`
        :raises NotImplementedError: if shape is not :code:`(6)`
        :return: `Numpy` array with shape :code:`(3, 3)`
        :rtype: :class:`numpy.ndarray`
        """        
        array = array.flatten()
        array_hat = np.empty((3,3))
        if len(array) == 6:
            array_hat = np.diag(array[0:3])
            array_hat[1,0] = array[3] / np.sqrt(2)
            array_hat[2,0] = array[4] / np.sqrt(2)
            array_hat[2,1] = array[5] / np.sqrt(2)
            array_hat[0,1] = array_hat[1,0]
            array_hat[0,2] = array_hat[2,0]
            array_hat[1,2] = array_hat[2,1]
        else:
            raise NotImplementedError
        return array_hat

    @staticmethod
    def cholesky(array):
        """Compute the Cholesky decomposition (https://en.wikipedia.org/wiki/Cholesky_decomposition)
        for a symmetric positive definite matrix in a given `NumPy` array.
        The elements of the lower triangular matrix are returned as a flattened `NumPy` array.

        The inverse function is given by :meth:`mlprum.data.Dataset.reverse_cholesky`.

        Example:
            >>> # Create a symmetric, positive definite matrix:
            >>> L = np.zeros((3,3))
            >>> L[np.tril_indices(3)] = np.arange(1,7)
            >>> M = L @ L.T
            >>> # Compute the Cholesky decomposition of the matrix:
            >>> data.Dataset.cholesky(M)
            array([1., 2., 3., 4., 5., 6.])

        :param array: `NumPy` array with shape :code:`(m, m)`
        :type array: :class:`numpy.ndarray`
        :raises ValueError: if array shape is not correct
        :return: `Numpy` array with the flattened Cholesky decomposition
        :rtype: :class:`numpy.ndarray`
        """        
        if array.shape[0] == array.shape[1]:
            array_hat = np.linalg.cholesky(array)[np.tril_indices(array.shape[0])]
        else:
            raise ValueError
        return array_hat

    @staticmethod
    def reverse_cholesky(array):
        """Reconstruct matrices from their Cholesky decompositions (https://en.wikipedia.org/wiki/Cholesky_decomposition),
        whose elements are given in flattened form by `array`.

        The inverse function is given by :meth:`mlprum.data.Dataset.cholesky`.

        Example:
            >>> # Reconstruct two matrices from its Cholesky decompositions:
            >>> L = np.arange(1,13).reshape(2,6)
            >>> print(L)
            [[ 1  2  3  4  5  6]
             [ 7  8  9 10 11 12]]
            >>> data.Dataset.reverse_cholesky(L)
            array([[[  1.,   2.,   4.],
                    [  2.,  13.,  23.],
                    [  4.,  23.,  77.]],
                   [[ 49.,  56.,  70.],
                    [ 56., 145., 179.],
                    [ 70., 179., 365.]]])

        :param array: `NumPy` array with shape :code:`(M)` or :code:`(N, M)`, where M is the m-th triangular number
        :type array: :class:`numpy.ndarray`
        :raises ValueError: if array shape is not correct
        :return: `Numpy` array with shape :code:`(m, m)` or :code:`(N, m, m)`
        :rtype: :class:`numpy.ndarray`
        """     
        if array.ndim == 1:   
            array = np.expand_dims(array, axis=0)
        N, M = array.shape
        m = np.sqrt(2 * M + 0.25) - 0.5
        if m == np.floor(m): # check if M is triangular number
            m = int(m)
        else:
            raise ValueError
        C_tril = np.zeros((N, m, m))
        idx0 = np.arange(N)
        idx1, idx2 = np.tril_indices(m)
        idx0, idx1, idx2 = np.repeat(idx0, array.shape[1]), np.tile(idx1, N), np.tile(idx2, N)
        C_tril[idx0, idx1, idx2] = array.flatten()
        C = np.einsum('nij,nkj->nik', C_tril, C_tril) # Einstein summation of C_tril @ C_tril.T

        if C.shape[0] == 1:
            C = np.squeeze(C, axis=0)
        return C

    @staticmethod
    def is_float(element) -> bool:
        try:
            float(element)
            return True
        except ValueError:
            return False
